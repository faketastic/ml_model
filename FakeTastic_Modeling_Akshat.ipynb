{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FakeTastic Modeling - Akshat.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "S-3gRvBwRr4l",
        "uvjnKE0YFnUv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvroYLweCkb1",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lAlR5Hl4et0",
        "colab_type": "code",
        "outputId": "459c7d36-ab33-4e87-baaa-aabb0d08048e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "! pip install pydrive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.6.7)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.11.3)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.12.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_6NmOHiBvs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Numpy\n",
        "import numpy as np\n",
        "\n",
        "# Pandas\n",
        "import pandas as pd\n",
        "\n",
        "# PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Scikit Learn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, cross_validate, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, Normalizer\n",
        "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression \n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import mean_squared_error, confusion_matrix, roc_auc_score, auc, average_precision_score, accuracy_score, average_precision_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import export_graphviz, DecisionTreeClassifier\n",
        "\n",
        "# # gensim\n",
        "from gensim import models\n",
        "import gensim.downloader as api\n",
        "from gensim.utils import lemmatize\n",
        "\n",
        "# scipy\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-3gRvBwRr4l",
        "colab_type": "text"
      },
      "source": [
        "## Helper Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMO2ojGxRq-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to plot coefs\n",
        "def plot_coefs(features, model):\n",
        "    # Check important features\n",
        "    # lr.coef_[0]\n",
        "    \n",
        "    colors = ['r']*10 + ['b']*10\n",
        "    \n",
        "    coefs = pd.DataFrame({'feature':feature_names, \n",
        "                          'coef':model.coef_[0]})\n",
        "    coefs.sort_values(by='coef', ascending=False, \n",
        "                      inplace=True)\n",
        "    top_pos = coefs[:10]\n",
        "    top_neg = coefs[-10:]\n",
        "    top_coefs = pd.concat([top_neg, top_pos]).sort_values(by='coef')\n",
        "\n",
        "    #Plot like in slides\n",
        "    top_coefs.plot.bar(x='feature', y='coef', color=colors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvjnKE0YFnUv",
        "colab_type": "text"
      },
      "source": [
        "## Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3DxDPcuC3Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_nNYTLvC5f6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get file links\n",
        "link_charlie = \"https://drive.google.com/open?id=1O29GXq_GE10w_dByM83tPFV5Ysz_aw-u\"\n",
        "link_ferguson = \"https://drive.google.com/open?id=1x--tPxfdWHE3K9Du4vCMTyVdqLXgc6eq\"\n",
        "link_germanwings = \"https://drive.google.com/open?id=1rTekmKthibm0KKEnXtx44IJ9vr2Oofzp\"\n",
        "link_ottawashooting = \"https://drive.google.com/open?id=1QIvIVM_pYSGw8nOXjXjmdmvFtetEKFN4\"\n",
        "link_sydneysiege = \"https://drive.google.com/open?id=1KH50vUC3Qb3mXbwk6qTJ77ZTsEdfwJ3h\"\n",
        "\n",
        "# Separate id from links\n",
        "link, id_charlie = link_charlie.split(\"=\")\n",
        "link, id_ferguson = link_ferguson.split(\"=\")\n",
        "link, id_germanwings = link_germanwings.split(\"=\")\n",
        "link, id_ottawashooting = link_ottawashooting.split(\"=\")\n",
        "link, id_sydneysiege = link_sydneysiege.split(\"=\")\n",
        "\n",
        "# Download Files\n",
        "downloaded = drive.CreateFile({'id':id_charlie}) \n",
        "downloaded.GetContentFile('charliehebdo_tweets.csv')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id_ferguson}) \n",
        "downloaded.GetContentFile('ferguson_tweets.csv')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id_germanwings}) \n",
        "downloaded.GetContentFile('germanwings_tweets.csv')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id_ottawashooting}) \n",
        "downloaded.GetContentFile('ottawashooting_tweets.csv')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id_sydneysiege}) \n",
        "downloaded.GetContentFile('sydneysiege_tweets.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HPq5IlHFqV0",
        "colab_type": "text"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p-Pag7jDetw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = pd.read_csv('charliehebdo_tweets.csv')\n",
        "df2 = pd.read_csv('ferguson_tweets.csv')\n",
        "df3 = pd.read_csv('germanwings_tweets.csv')\n",
        "df4 = pd.read_csv('ottawashooting_tweets.csv')\n",
        "df5 = pd.read_csv('sydneysiege_tweets.csv')\n",
        "\n",
        "df = [df1, df2, df3, df4, df5]\n",
        "\n",
        "data = pd.concat(df)\n",
        "\n",
        "data.is_fake = data.is_fake.astype(int)\n",
        "data.retweet = data.retweet.astype(int)\n",
        "data.user_verified = data.user_verified.astype(int)\n",
        "data = data.drop(columns=['tweet_hashtag'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PARhSLXNIeAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.groupby('is_fake').describe().T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pizdRLwBKZ8q",
        "colab_type": "code",
        "outputId": "122b015f-d7d7-4925-fcc6-ea11726ddb39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['tweet_id', 'tweet_text', 'retweet', 'retweet_source_id',\n",
              "       'retweet_count', 'is_fake', 'user_verified', 'user_followers_count',\n",
              "       'user_statuses_count', 'user_friends_count', 'user_favourites_count',\n",
              "       'tweet_relative_age'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oIczkp2A1K-",
        "colab_type": "text"
      },
      "source": [
        "## Word2Vec Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNTE3JiI_Ojo",
        "colab_type": "code",
        "outputId": "72802aff-ac61-423f-dd9d-b1c7bff7fe3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = api.load(\"glove-twitter-200\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[===============================================---] 94.4% 716.4/758.5MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vA0jrCLDRey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data.tweet_text\n",
        "y = data.is_fake\n",
        "\n",
        "# Separate into training and validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
        "                                                  stratify=y, \n",
        "                                                  random_state=7)\n",
        "\n",
        "# Convert input to list of strings\n",
        "X_train_vector = X_train.values.squeeze()\n",
        "\n",
        "vect = CountVectorizer(stop_words='english')\n",
        "X_train_vec = vect.fit_transform(X_train_vector)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpOSJvvgE997",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_X_train = vect.inverse_transform(X_train_vec)\n",
        "tokenized_X_train = np.array(tokenized_X_train)\n",
        "y_train = y_train.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9UqgORRFRKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = list(model.vocab.keys())\n",
        "\n",
        "# Convert vocab to set for \n",
        "# taking intersection later\n",
        "vocab_set = set(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb1OE5GWHDuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subset = tokenized_X_train\n",
        "\n",
        "new_subset = []\n",
        "y_sub = []\n",
        "for i in range(len(subset)):\n",
        "    req = vocab_set.intersection(set(subset[i]))\n",
        "    if len(req) != 0:\n",
        "        new_subset.append(list(req))\n",
        "        y_sub.append(y_train[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nheI7HRlHL_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Form training set of word vectors\n",
        "train_set = np.array([np.mean(model[new_subset[i]], axis=0) \n",
        "                      for i in range(len(new_subset))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppMR1iUFLaVq",
        "colab_type": "text"
      },
      "source": [
        "### Grid Search Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4B9FALtHOJ4",
        "colab_type": "code",
        "outputId": "1c855dca-d9aa-4272-c239-900a04f994c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "params = {'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "grid_lr = GridSearchCV(LogisticRegression(), param_grid=params,\n",
        "                      n_jobs=-1, cv=5)\n",
        "\n",
        "# fir grid\n",
        "grid_lr.fit(train_set, y_sub)\n",
        "\n",
        "\n",
        "grid_lr.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7211180042412507"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWIZPclsLgoH",
        "colab_type": "text"
      },
      "source": [
        "### Grid Search Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2RL60c0JT_L",
        "colab_type": "code",
        "outputId": "62adf6c5-df5b-4744-f584-90ec3c253354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "params = {'n_estimators':[50, 100],\n",
        "          'max_depth': [10, 20, 50, 100]}\n",
        "\n",
        "grid_rf = GridSearchCV(RandomForestClassifier(), param_grid=params,\n",
        "                      n_jobs=-1, cv=5)\n",
        "\n",
        "# fir grid\n",
        "grid_rf.fit(train_set, y_sub)\n",
        "\n",
        "\n",
        "grid_rf.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7400324021021851"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYGAHdO-g2RJ",
        "colab_type": "text"
      },
      "source": [
        "### Grid Search Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3wN7Lgig1xx",
        "colab_type": "code",
        "outputId": "ba6a536d-7b7b-4e35-ec85-d8025235ab01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "params = {'n_estimators':[50, 100],\n",
        "          'learning_rate':[0.1, 0.3, 0.5],\n",
        "          'max_features': ['auto', 'sqrt', 'log2']}\n",
        "\n",
        "grid_gb = GridSearchCV(GradientBoostingClassifier(), param_grid=params,\n",
        "                      n_jobs=-1, cv=5)\n",
        "\n",
        "# fir grid\n",
        "grid_gb.fit(train_set, y_sub)\n",
        "\n",
        "\n",
        "grid_gb.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7297980795827241"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pKI28trI1XD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}